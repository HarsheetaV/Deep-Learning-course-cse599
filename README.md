# Deep-Learning-course-cse599

Deep Learning Course Assignment Submission:

This repository contains my assignment submission for the Deep Learning course. It includes models built from scratch in various domains such as Computer Vision, Machine Learning Classifiers, and Natural Language Processing.
Structure of the Repository

The repository is organized into the following sections:

Computer Vision from scratch:

This section focuses on building computer vision models from scratch. It includes the following components:

Batch Normalization: Implementation of batch normalization techniques.

Convolutional Networks: Implementation of convolutional neural networks (CNNs) without using any existing libraries.

Fully connected Nets: Implementation of fully connected neural networks from scratch.

Network Visualization: Techniques for visualizing and interpreting neural network architectures.

PyTorch: Utilizing PyTorch library for building computer vision models.

Machine Learning Classifiers:
This section covers various machine learning classifiers implemented from scratch. It includes the following classifiers:

Features Extraction Classifier: A classifier that performs feature extraction for data classification.

KNN Classifier: Implementation of the K-Nearest Neighbors (KNN) classifier algorithm.

Softmax Classifier: Implementation of the Softmax classifier algorithm.

SVM Classifier: Implementation of the Support Vector Machine (SVM) classifier algorithm.

Two Layer Net Classifier: A two-layer neural network classifier implemented without using external libraries.

Natural Language Processing from scratch:

This section focuses on building natural language processing models from scratch. It includes the following components:

Generative Adversarial Networks: Implementation of Generative Adversarial Networks (GANs) for text generation.

LSTM Captioning: Implementation of a captioning model using Long Short-Term Memory (LSTM) networks.

RNN Captioning: Implementation of a captioning model using Recurrent Neural Networks (RNNs).

Self-Supervised Learning: Techniques for self-supervised learning in natural language processing.

Transformer Captioning: Implementation of a captioning model using the Transformer architecture.
